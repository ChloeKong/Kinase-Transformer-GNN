{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPNN训练 Lipo数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 添加包环境路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/yuekong/Desktop/Github/Kinase-Transformer-GNN')\n",
    "from molecular_network.mol_dataset import Dataset\n",
    "from molecular_network.util import modelEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, ReLU, GRU\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import NNConv, Set2Set\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.utils import remove_self_loops\n",
    "from molecular_network.util import modelEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文件路径定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'Lipo'\n",
    "root = '/Users/yuekong/Desktop/Github/Kinase-Transformer-GNN/data/%s'%(dataset_name)\n",
    "path_ckpt = '../checkpoints/%s.ckpt'%(dataset_name)\n",
    "path_prds = '../results_saved/%s/prds.pkl'%(dataset_name)\n",
    "path_pfms =  '../results_saved/%s/performance.csv'%(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型超参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 2\n",
    "dim = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([4200])"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "dataset = Dataset(root,'Lipophilicity.csv').shuffle()\n",
    "dataset.data.y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 归一化数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "数据集含4200个化合物\n"
    }
   ],
   "source": [
    "# Normalize targets to mean = 0 and std = 1.\n",
    "mean = dataset.data.y.mean(dim=0, keepdim=True)\n",
    "std = dataset.data.y.std(dim=0, keepdim=True)\n",
    "dataset.data.y = (dataset.data.y - mean) / std ## 只考虑第1个性质\n",
    "length = dataset.data.y.shape[0]\n",
    "print('数据集含%i个化合物'%(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Data(edge_attr=[247798, 5], edge_index=[2, 247798], x=[113565, 31], y=[4200])"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "dataset.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 划分训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "test set 含 420 样本\n"
    }
   ],
   "source": [
    "# 划分比例 tr: val : te = 8:1:1 \n",
    "split = length//10\n",
    "print('test set 含 %i 样本'%(split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "------loader loaded------\n"
    }
   ],
   "source": [
    "# Split datasets.\n",
    "\n",
    "test_dataset = dataset[:split]\n",
    "val_dataset = dataset[split:2*split]\n",
    "train_dataset = dataset[2*split:]\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "print('------loader loaded------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lin0 = torch.nn.Linear(dataset.num_features, dim)\n",
    "\n",
    "        # 这个nn是每个节点在message中用到的网络,5对应边特征数 \n",
    "        # 注：此脚本中transform部分把edge_attr变成了5，而不是本来的4\n",
    "        nn = Sequential(Linear(5, 128), ReLU(), Linear(128, dim * dim))\n",
    "        self.conv = NNConv(dim, dim, nn, aggr='mean')\n",
    "        self.gru = GRU(dim, dim)\n",
    "\n",
    "        self.set2set = Set2Set(dim, processing_steps=3)\n",
    "        self.lin1 = torch.nn.Linear(2 * dim, dim)\n",
    "        self.lin2 = torch.nn.Linear(dim, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        out = F.relu(self.lin0(data.x))\n",
    "        h = out.unsqueeze(0)\n",
    "\n",
    "        for i in range(3):\n",
    "            m = F.relu(self.conv(out, data.edge_index, data.edge_attr))\n",
    "            out, h = self.gru(m.unsqueeze(0), h)\n",
    "            out = out.squeeze(0)\n",
    "\n",
    "        out = self.set2set(out, data.batch)\n",
    "        out = F.relu(self.lin1(out))\n",
    "        out = self.lin2(out)\n",
    "        return out.view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练前"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
    "                                                       factor=0.7, patience=5,\n",
    "                                                       min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义训练+测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "     \n",
    "        x = model(data)\n",
    "        x = x.to(torch.float64)\n",
    "        loss = F.mse_loss(x, data.y)\n",
    "        loss.backward()\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    test_prds = []\n",
    "    model.eval()\n",
    "    error = 0\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        y_prd = model(data)\n",
    "        error += (y_prd * std - data.y * std).abs().sum().item()  # MAE\n",
    "        test_prds.append(y_prd)\n",
    "    test_prds = torch.cat(test_prds)\n",
    "\n",
    "    return error / len(loader.dataset), test_prds # 把预测的结果保存出来"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "-----------training begin-------------\nEpoch: 001, LR: 0.001000, Loss: 0.8167145, Validation MAE: 0.8208229, Test MAE: 0.7846891\n-----------training begin-------------\nEpoch: 002, LR: 0.001000, Loss: 0.7605780, Validation MAE: 0.8319625, Test MAE: 0.7846891\n"
    }
   ],
   "source": [
    "best_val_error = None\n",
    "for epoch in range(1, n_epoch+1):\n",
    "    print('-----------training begin-------------')\n",
    "    lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "    loss = train(epoch)\n",
    "    val_error, val_prds = test(val_loader)\n",
    "    scheduler.step(val_error)\n",
    "\n",
    "    if best_val_error is None or val_error <= best_val_error:\n",
    "        test_error, test_prds = test(test_loader)\n",
    "        best_val_error = val_error\n",
    "\n",
    "    print('Epoch: {:03d}, LR: {:7f}, Loss: {:.7f}, Validation MAE: {:.7f}, '\n",
    "          'Test MAE: {:.7f}'.format(epoch, lr, loss, val_error, test_error))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "torch.save(model.state_dict(), path_ckpt)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载模型（中断时，重载模型，再运行额外epoch）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# 加载\n",
    "model.load_state_dict(torch.load(path_ckpt))\n",
    "# 测试时不启用 BatchNormalization 和 Dropout\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意：奇怪！   \n",
    "原因是：test_dataset是一个包含了很多Data类型的Dataset类型（molecular_network.mol_dataset.dataset.Dataset）\n",
    "此类型若直接调用XX.data 则得到原始Dataset的总data\n",
    "解决方法，遍历test_dataset,获取每个y值，再合并，再转化成numpy类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  保存测试集真实值+预测值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "------------------predictions save in ../results_saved/Lipo/prds.pkl------------\n"
    }
   ],
   "source": [
    "\n",
    "# 读取预测值\n",
    "test_prds = test_prds.detach().numpy() # 转成numpy\n",
    "\n",
    "# 读取真实值\n",
    "test_ys = [test_dataset[i].y for i in range(len(test_dataset))]\n",
    "test_true = torch.cat(test_ys).numpy()\n",
    "\n",
    "# 保存真实值和预测值文件\n",
    "df = pd.DataFrame()\n",
    "df['test_true'] = test_true\n",
    "df['test_pred'] = test_prds\n",
    "\n",
    "df.to_pickle(path_prds)\n",
    "print('------------------predictions save in %s------------' %path_prds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "model kind: rgs\nperformance dict: {'r2': 0.243, 'rmse': 0.807, 'mae': 0.652}\n------------------predictions save in ../results_saved/Lipo/performance.csv------------\n"
    }
   ],
   "source": [
    "pfm = modelEvaluator(test_true,test_prds)\n",
    "df = pd.DataFrame(pfm.get_performance(), index=['test_set']) # 若不指定index么，会报错\n",
    "\n",
    "df.to_csv(path_pfms)\n",
    "print('------------------predictions save in %s------------' %path_pfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595498261332",
   "display_name": "Python 3.6.10 64-bit ('torch': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}